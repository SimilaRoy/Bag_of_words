{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCALvSGumEo"
      },
      "source": [
        "## Unigrams\n",
        "\n",
        "Unigrams are the simplest form of n-grams, where each word is considered as a single token. The table for unigrams from the sentence \"The quick brown fox\" would look like this:\n",
        "\n",
        "**Unigrams**\n",
        "\n",
        "| Words |\n",
        "|-------|\n",
        "| The   |\n",
        "| quick |\n",
        "| brown |\n",
        "| fox   |\n",
        "\n",
        "\n",
        "Explanation: Each word is treated as an individual entity. Unigrams don't capture any context or word order, just the presence of words.\n",
        "\n",
        "## Bigrams\n",
        "\n",
        "Bigrams are pairs of consecutive words. They can provide more context compared to unigrams by capturing the immediate word relationships. The bigrams for our sentence are shown in the table below:\n",
        "\n",
        "**Bigrams**\n",
        "\n",
        "|    | Phrases    |\n",
        "|----|------------|\n",
        "| 0  | The quick  |\n",
        "| 1  | quick brown|\n",
        "| 2  | brown fox  |\n",
        "\n",
        "\n",
        "Explanation: Each entry represents a pair of adjacent words from the sentence. Bigrams help in understanding the text better by capturing the local context, which is particularly useful for tasks like predictive text input or sentiment analysis.\n",
        "\n",
        "## Trigrams\n",
        "\n",
        "Trigrams consist of three consecutive words, offering an even broader context than bigrams. Here's how the trigrams from the sentence would be tabulated:\n",
        "\n",
        "**Trigrams**\n",
        "\n",
        "|    | Phrases          |\n",
        "|----|------------------|\n",
        "| 0  | The quick brown  |\n",
        "| 1  | quick brown fox  |\n",
        "\n",
        "\n",
        "**Explanation:** Trigrams capture a wider scope of context than bigrams, reflecting the flow of ideas or concepts within the text. They are particularly valuable in language modeling and translation, where understanding the sequence of words is crucial.\n",
        "\n",
        "**Understanding the Tables**\n",
        "\n",
        "**Unigrams Table:** Shows individual words. While it's good for basic text analysis, it lacks contextual information.\n",
        "\n",
        "**Bigrams Table:** Provides pairs of consecutive words, introducing a basic level of context and sequence, which is absent in unigrams.\n",
        "\n",
        "**Trigrams Table:** Offers a richer context by including sequences of three words, making it more effective for capturing the nuances of language.\n",
        "\n",
        "Using these n-grams, we can build features for machine learning models in natural language processing tasks. Unigrams are useful for general frequency-based analysis but might miss out on context. Bigrams and trigrams capture more of the sentence structure, which can be crucial for understanding the meaning, sentiment, or intent of the text, especially in nuanced or complex linguistic scenarios. Higher-order n-grams (like trigrams) can be particularly useful in tasks requiring a deeper understanding of context, such as speech recognition, machine translation, or sentiment analysis, where the exact sequence of words significantly impacts the meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uy38WSAEumEw"
      },
      "outputs": [],
      "source": [
        "#pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viupMT-lumE1",
        "outputId": "4abe0f7c-f614-4135-ec87-d09bfb62d5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams:\n",
            " ['brown' 'fox' 'quick' 'the']\n",
            "\n",
            "Bigrams:\n",
            " ['brown fox' 'quick brown' 'the quick']\n",
            "\n",
            "Trigrams:\n",
            " ['quick brown fox' 'the quick brown']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample text\n",
        "text = [\"The quick brown fox\"]\n",
        "\n",
        "# Initialize CountVectorizer for unigrams\n",
        "vectorizer_unigrams = CountVectorizer(ngram_range=(1, 1))\n",
        "unigrams = vectorizer_unigrams.fit_transform(text)\n",
        "\n",
        "# Initialize CountVectorizer for bigrams\n",
        "vectorizer_bigrams = CountVectorizer(ngram_range=(2, 2))\n",
        "bigrams = vectorizer_bigrams.fit_transform(text)\n",
        "\n",
        "# Initialize CountVectorizer for trigrams\n",
        "vectorizer_trigrams = CountVectorizer(ngram_range=(3, 3))\n",
        "trigrams = vectorizer_trigrams.fit_transform(text)\n",
        "\n",
        "# Convert to arrays and get feature names\n",
        "unigram_features = vectorizer_unigrams.get_feature_names_out()\n",
        "bigram_features = vectorizer_bigrams.get_feature_names_out()\n",
        "trigram_features = vectorizer_trigrams.get_feature_names_out()\n",
        "\n",
        "# Print the results\n",
        "print(\"Unigrams:\\n\", unigram_features)\n",
        "print(\"\\nBigrams:\\n\", bigram_features)\n",
        "print(\"\\nTrigrams:\\n\", trigram_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgT4TTnDumE5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}